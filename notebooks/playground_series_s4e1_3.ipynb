{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "255aafef-661c-4a19-b25f-feda4e1dc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "import optuna\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f31d5b5f-60b7-46a6-a7a2-476c68d2f8e1",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45370fd8-bec0-4316-90d5-47b3a7470089",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset):\n",
    "    train_url = os.path.join('../data/playground_series_s4e1', \n",
    "                         'train.csv')\n",
    "    test_url = os.path.join('../data/playground_series_s4e1', \n",
    "                            'test.csv')\n",
    "    origin_url = os.path.join('../data/playground_series_s4e1', \n",
    "                              'Churn_Modelling.csv')\n",
    "    if dataset == 'train':\n",
    "        df = pd.read_csv(train_url)\n",
    "    elif dataset == 'test':\n",
    "        df = pd.read_csv(test_url)\n",
    "    elif dataset == 'origin':\n",
    "        df = pd.read_csv(origin_url)\n",
    "    else:\n",
    "        raise ValueError(f'{dataset} is not a supported dataset')\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3febde-9e10-4955-8620-fc538c484208",
   "metadata": {},
   "source": [
    "### Target Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6af5ff70-ac55-4e2b-8db2-1ce694654def",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_target(df, col):\n",
    "    # calcualted the mean exited rate by specified columns\n",
    "    df_target = df.groupby(col).agg({'exited': 'mean'})\n",
    "    df_target = df_target.reset_index()\n",
    "    df_target = df_target.rename(columns={'exited': col+'_target'})\n",
    "    \n",
    "    df = pd.merge(df, df_target, on=col, how='left', \n",
    "                  validate='m:1')\n",
    "    df = df.drop(columns=[col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b34058f-95af-4135-8100-eb993b8d9bd0",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "Accuracy: roc_auc\n",
    "1. logistic regression\n",
    "2. catboost classifier\n",
    "3. xgboost classifier\n",
    "4. lightgbm classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aeb43cc-a8ea-4b60-9242-738693b6b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_score(df, model='lr', scaler='minmax'):\n",
    "    \n",
    "    X_train = df.drop(columns=['exited'])\n",
    "    y_train = df['exited']\n",
    "    \n",
    "    # stadardization\n",
    "    if scaler == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        raise ValueError(f'{scaler} is not supported')\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    # cross validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    if model == 'lr':\n",
    "        model = LogisticRegression()\n",
    "    elif model == 'cat':\n",
    "        model = CatBoostClassifier(verbose=0)\n",
    "    elif model == 'xgb':\n",
    "        model = XGBClassifier(verbosity=0)\n",
    "    elif model == 'lgb': \n",
    "        model = LGBMClassifier(verbose=-1)\n",
    "    else:\n",
    "        model = model\n",
    "    scores = cross_val_score(model, X_train_scaled, y_train, cv=skf, scoring='roc_auc')\n",
    "    \n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6a8712-6263-4e39-97aa-f8f793550559",
   "metadata": {},
   "source": [
    "### Generated Dataset\n",
    "The highest roc auc score of **0.9000** is achieved by lightgbm classifier with minmax scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "edc9c435-03f7-4aca-a6a4-3c65e3ba7d9b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score of lr with minmax is  0.8353.\n",
      "The average score of lr with standard is  0.8353.\n",
      "The average score of cat with minmax is  0.8996.\n",
      "The average score of cat with standard is  0.8995.\n",
      "The average score of xgb with minmax is  0.8981.\n",
      "The average score of xgb with standard is  0.8982.\n",
      "The average score of lgb with minmax is  0.9000.\n",
      "The average score of lgb with standard is  0.8998.\n",
      "CPU times: total: 30min 43s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the data\n",
    "train_df = load_data('train')\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "train_df = train_df.drop(columns=['id', 'customerid'])\n",
    "#train_df = train_df.drop(columns=['id'])\n",
    "\n",
    "# impute the dataset\n",
    "cols = ['surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "#cols = ['customerid', 'surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "for col in cols:\n",
    "    train_df = impute_target(train_df, col)\n",
    "    \n",
    "# calculate the roc scores\n",
    "for model in ['lr', 'cat', 'xgb', 'lgb']:\n",
    "    for scaler in ['minmax', 'standard']: \n",
    "        scores = calculate_score(train_df, model=model, scaler=scaler)\n",
    "        print(f'The average score of {model} with {scaler} is {scores.mean(): .4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b61003-d192-4da8-8bf3-105ec885649d",
   "metadata": {},
   "source": [
    "### Original Dataset\n",
    "The highest auc score of **0.9341** is achieved by catboost classifier with minmax/standard scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "352360af-22e4-4de0-a02c-f320243df134",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score of lr with minmax is  0.8841.\n",
      "The average score of lr with standard is  0.8843.\n",
      "The average score of cat with minmax is  0.9341.\n",
      "The average score of cat with standard is  0.9341.\n",
      "The average score of xgb with minmax is  0.9244.\n",
      "The average score of xgb with standard is  0.9244.\n",
      "The average score of lgb with minmax is  0.9310.\n",
      "The average score of lgb with standard is  0.9316.\n",
      "CPU times: total: 6min 39s\n",
      "Wall time: 36.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the data\n",
    "train_df = load_data('origin')\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "train_df = train_df.rename(columns={'rownumber': 'id'})\n",
    "\n",
    "# drop the rows with missing values and useless columns\n",
    "train_df = train_df.dropna(how='any', axis=0)\n",
    "train_df = train_df.drop(columns=['id', 'customerid'])\n",
    "\n",
    "# impute the dataset\n",
    "cols = ['surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "#cols = ['customerid', 'surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "for col in cols:\n",
    "    train_df = impute_target(train_df, col)\n",
    "    \n",
    "# calculate the roc scores\n",
    "for model in ['lr', 'cat', 'xgb', 'lgb']:\n",
    "    for scaler in ['minmax', 'standard']: \n",
    "        scores = calculate_score(train_df, model=model, scaler=scaler)\n",
    "        print(f'The average score of {model} with {scaler} is {scores.mean(): .4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e650c8-4fa4-41d0-a2cf-a701ad10a2f4",
   "metadata": {},
   "source": [
    "### Original + Generated Dataset\n",
    "The highest auc score of **0.8982** is achieved by lightgbm classifier with minmax scaler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a415bb37-305e-4da4-bd56-55e03cd1aab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score of lr with minmax is  0.8312.\n",
      "The average score of lr with standard is  0.8312.\n",
      "The average score of cat with minmax is  0.8977.\n",
      "The average score of cat with standard is  0.8976.\n",
      "The average score of xgb with minmax is  0.8962.\n",
      "The average score of xgb with standard is  0.8963.\n",
      "The average score of lgb with minmax is  0.8982.\n",
      "The average score of lgb with standard is  0.8981.\n",
      "CPU times: total: 31min 47s\n",
      "Wall time: 3min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the generated dataset\n",
    "train_df = load_data('train')\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "train_df = train_df.drop(columns=['id', 'customerid'])\n",
    "\n",
    "# load the original dataset\n",
    "origin_df = load_data('origin')\n",
    "origin_df.columns = origin_df.columns.str.lower()\n",
    "origin_df = origin_df.rename(columns={'rownumber': 'id'})\n",
    "origin_df = origin_df.dropna(how='any', axis=0)\n",
    "origin_df = origin_df.drop(columns=['id', 'customerid'])\n",
    "\n",
    "# concat the data\n",
    "train_df = pd.concat([train_df, origin_df], ignore_index=True)\n",
    "\n",
    "# impute the dataset\n",
    "cols = ['surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "for col in cols:\n",
    "    train_df = impute_target(train_df, col)\n",
    "    \n",
    "# calculate the roc scores\n",
    "for model in ['lr', 'cat', 'xgb', 'lgb']:\n",
    "    for scaler in ['minmax', 'standard']: \n",
    "        scores = calculate_score(train_df, model=model, scaler=scaler)\n",
    "        print(f'The average score of {model} with {scaler} is {scores.mean(): .4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3cc48b-e21c-4dcd-910c-026d4adf1332",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "The highest auc score of **0.8998** is achieved with 20 trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f2a4f16e-9448-445c-b365-5516e6218878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial, X, y):\n",
    "    \n",
    "    param_grid = {\n",
    "        \n",
    "        # tree structure\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12, step=1),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 20, 3000, step=20), \n",
    "\n",
    "        # better accuracy\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.9, step=0.01),\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [10000]),\n",
    "\n",
    "        # combat overfitting\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.2, 0.99, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.2, 0.99, log=True),\n",
    "        'subsample_freq': trial.suggest_categorical('subsample_freq', [1]), \n",
    "        'reg_alpha': trial.suggest_categorical('reg_alpha', [0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0]), # L1 regularization\n",
    "        'reg_lambda': trial.suggest_categorical('reg_lambda', [0.1, 0.5, 1.0, 5.0, 10.0, 50.0, 100.0]), # L2 regularization\n",
    "\n",
    "        'random_state': trial.suggest_categorical('random_state', [42]), \n",
    "        'n_jobs': trial.suggest_categorical('n_jobs', [-1]), \n",
    "        #'early_stopping_rounds': trial.suggest_categorical('early_stopping_rounds', [100]), \n",
    "        'metric': trial.suggest_categorical('metric', ['auc']), \n",
    "    }\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    cv_scores = np.empty(5)\n",
    "    for idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        model = LGBMClassifier(objective='binary', **param_grid)\n",
    "        model.fit(\n",
    "            X_train, \n",
    "            y_train, \n",
    "            eval_set=[(X_test, y_test)], \n",
    "            early_stopping_rounds=100, \n",
    "            verbose=0, \n",
    "        )\n",
    "        y_preds = model.predict_proba(X_test)[:, 1]\n",
    "        cv_scores[idx] = roc_auc_score(y_test, y_preds)\n",
    "    \n",
    "    return np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15062134-1809-4d0d-9a15-6e87df106a7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2024-01-05 14:40:41,805]\u001b[0m A new study created in memory with name: XGB Classifier\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:40:55,074]\u001b[0m Trial 0 finished with value: 0.8954198479781935 and parameters: {'max_depth': 6, 'num_leaves': 2860, 'learning_rate': 0.66, 'n_estimators': 10000, 'colsample_bytree': 0.5210282738918683, 'subsample': 0.25668551069752277, 'subsample_freq': 1, 'reg_alpha': 100.0, 'reg_lambda': 0.1, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 0 with value: 0.8954198479781935.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:01,354]\u001b[0m Trial 1 finished with value: 0.8982810969500473 and parameters: {'max_depth': 5, 'num_leaves': 1840, 'learning_rate': 0.13, 'n_estimators': 10000, 'colsample_bytree': 0.3191208553648477, 'subsample': 0.3593410534932508, 'subsample_freq': 1, 'reg_alpha': 0.5, 'reg_lambda': 5.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 1 with value: 0.8982810969500473.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:06,946]\u001b[0m Trial 2 finished with value: 0.8965546706318523 and parameters: {'max_depth': 9, 'num_leaves': 1340, 'learning_rate': 0.11, 'n_estimators': 10000, 'colsample_bytree': 0.4415526055389373, 'subsample': 0.21130824410949353, 'subsample_freq': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 1 with value: 0.8982810969500473.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:10,180]\u001b[0m Trial 3 finished with value: 0.8972011779100069 and parameters: {'max_depth': 4, 'num_leaves': 140, 'learning_rate': 0.3, 'n_estimators': 10000, 'colsample_bytree': 0.372397933026908, 'subsample': 0.3086813876107726, 'subsample_freq': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.1, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 1 with value: 0.8982810969500473.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:27,787]\u001b[0m Trial 4 finished with value: 0.8987502266669025 and parameters: {'max_depth': 10, 'num_leaves': 240, 'learning_rate': 0.33, 'n_estimators': 10000, 'colsample_bytree': 0.240720594227879, 'subsample': 0.79532772562309, 'subsample_freq': 1, 'reg_alpha': 50.0, 'reg_lambda': 0.1, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 4 with value: 0.8987502266669025.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:34,099]\u001b[0m Trial 5 finished with value: 0.8961439890684195 and parameters: {'max_depth': 7, 'num_leaves': 1580, 'learning_rate': 0.39, 'n_estimators': 10000, 'colsample_bytree': 0.20829855311222006, 'subsample': 0.2376686732364553, 'subsample_freq': 1, 'reg_alpha': 10.0, 'reg_lambda': 50.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 4 with value: 0.8987502266669025.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:38,789]\u001b[0m Trial 6 finished with value: 0.8877279688176787 and parameters: {'max_depth': 9, 'num_leaves': 2620, 'learning_rate': 0.73, 'n_estimators': 10000, 'colsample_bytree': 0.2695395683458523, 'subsample': 0.833692925820031, 'subsample_freq': 1, 'reg_alpha': 1.0, 'reg_lambda': 0.5, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 4 with value: 0.8987502266669025.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:42,988]\u001b[0m Trial 7 finished with value: 0.8996441654336318 and parameters: {'max_depth': 6, 'num_leaves': 2840, 'learning_rate': 0.3, 'n_estimators': 10000, 'colsample_bytree': 0.45854784702382184, 'subsample': 0.6156737246940783, 'subsample_freq': 1, 'reg_alpha': 0.5, 'reg_lambda': 50.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 7 with value: 0.8996441654336318.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:46,183]\u001b[0m Trial 8 finished with value: 0.8928276524398978 and parameters: {'max_depth': 4, 'num_leaves': 1480, 'learning_rate': 0.89, 'n_estimators': 10000, 'colsample_bytree': 0.29455258989577426, 'subsample': 0.5860016532666615, 'subsample_freq': 1, 'reg_alpha': 0.1, 'reg_lambda': 0.5, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 7 with value: 0.8996441654336318.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:41:50,959]\u001b[0m Trial 9 finished with value: 0.8991793283213397 and parameters: {'max_depth': 3, 'num_leaves': 1540, 'learning_rate': 0.21000000000000002, 'n_estimators': 10000, 'colsample_bytree': 0.5612681136371762, 'subsample': 0.2643296152216003, 'subsample_freq': 1, 'reg_alpha': 1.0, 'reg_lambda': 0.1, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 7 with value: 0.8996441654336318.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:43:17,729]\u001b[0m Trial 10 finished with value: 0.899748820128538 and parameters: {'max_depth': 12, 'num_leaves': 2300, 'learning_rate': 0.01, 'n_estimators': 10000, 'colsample_bytree': 0.8883901078521625, 'subsample': 0.4942057443081356, 'subsample_freq': 1, 'reg_alpha': 0.5, 'reg_lambda': 50.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 10 with value: 0.899748820128538.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:44:45,133]\u001b[0m Trial 11 finished with value: 0.8997860160451989 and parameters: {'max_depth': 12, 'num_leaves': 2360, 'learning_rate': 0.01, 'n_estimators': 10000, 'colsample_bytree': 0.9451054509103135, 'subsample': 0.5264404725074582, 'subsample_freq': 1, 'reg_alpha': 0.5, 'reg_lambda': 50.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:46:16,328]\u001b[0m Trial 12 finished with value: 0.899654912593418 and parameters: {'max_depth': 12, 'num_leaves': 2220, 'learning_rate': 0.01, 'n_estimators': 10000, 'colsample_bytree': 0.9882965572410699, 'subsample': 0.45165893640706734, 'subsample_freq': 1, 'reg_alpha': 5.0, 'reg_lambda': 50.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:46:43,583]\u001b[0m Trial 13 finished with value: 0.8980423676152769 and parameters: {'max_depth': 12, 'num_leaves': 2320, 'learning_rate': 0.03, 'n_estimators': 10000, 'colsample_bytree': 0.9756683714940833, 'subsample': 0.4524282060169002, 'subsample_freq': 1, 'reg_alpha': 0.5, 'reg_lambda': 1.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:46:52,192]\u001b[0m Trial 14 finished with value: 0.8949533734216661 and parameters: {'max_depth': 11, 'num_leaves': 860, 'learning_rate': 0.51, 'n_estimators': 10000, 'colsample_bytree': 0.7356024782336295, 'subsample': 0.6024186804240438, 'subsample_freq': 1, 'reg_alpha': 0.5, 'reg_lambda': 10.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:47:03,822]\u001b[0m Trial 15 finished with value: 0.8991731176547242 and parameters: {'max_depth': 10, 'num_leaves': 2160, 'learning_rate': 0.17, 'n_estimators': 10000, 'colsample_bytree': 0.7283109914960222, 'subsample': 0.38905196709600104, 'subsample_freq': 1, 'reg_alpha': 0.5, 'reg_lambda': 100.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:47:12,743]\u001b[0m Trial 16 finished with value: 0.8970267272197834 and parameters: {'max_depth': 12, 'num_leaves': 2560, 'learning_rate': 0.56, 'n_estimators': 10000, 'colsample_bytree': 0.7726925716093459, 'subsample': 0.5214156145423081, 'subsample_freq': 1, 'reg_alpha': 5.0, 'reg_lambda': 50.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:47:23,450]\u001b[0m Trial 17 finished with value: 0.899579140133714 and parameters: {'max_depth': 8, 'num_leaves': 1920, 'learning_rate': 0.22, 'n_estimators': 10000, 'colsample_bytree': 0.8349234995118109, 'subsample': 0.9546504099937784, 'subsample_freq': 1, 'reg_alpha': 50.0, 'reg_lambda': 50.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:48:17,705]\u001b[0m Trial 18 finished with value: 0.8992578441182552 and parameters: {'max_depth': 11, 'num_leaves': 1060, 'learning_rate': 0.06999999999999999, 'n_estimators': 10000, 'colsample_bytree': 0.6290731767338311, 'subsample': 0.7088293789631352, 'subsample_freq': 1, 'reg_alpha': 100.0, 'reg_lambda': 10.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n",
      "\u001b[32m[I 2024-01-05 14:48:23,863]\u001b[0m Trial 19 finished with value: 0.8988372793987731 and parameters: {'max_depth': 11, 'num_leaves': 2500, 'learning_rate': 0.41000000000000003, 'n_estimators': 10000, 'colsample_bytree': 0.6539303509997679, 'subsample': 0.5022608563317287, 'subsample_freq': 1, 'reg_alpha': 10.0, 'reg_lambda': 100.0, 'random_state': 42, 'n_jobs': -1, 'metric': 'auc'}. Best is trial 11 with value: 0.8997860160451989.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1h 54min 31s\n",
      "Wall time: 7min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the data\n",
    "train_df = load_data('train')\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "train_df = train_df.drop(columns=['id', 'customerid'])\n",
    "#train_df = train_df.drop(columns=['id'])\n",
    "\n",
    "# impute the dataset\n",
    "cols = ['surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "#cols = ['customerid', 'surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "for col in cols:\n",
    "    train_df = impute_target(train_df, col)\n",
    "\n",
    "X_train = train_df.drop(columns=['exited'])\n",
    "y_train = train_df['exited']\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "sampler = optuna.samplers.TPESampler(seed=42)\n",
    "study = optuna.create_study(direction='maximize', study_name='XGB Classifier', sampler=sampler)\n",
    "func = lambda trial: objective(trial, X_train_scaled, y_train)\n",
    "study.optimize(func, n_trials=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7d4297b3-2d01-48f3-bf6a-c7f795e38fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score of the optimized model is  0.8893.\n",
      "CPU times: total: 4h 2min 6s\n",
      "Wall time: 16min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# load the data\n",
    "train_df = load_data('train')\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "\n",
    "# drop the rows with missing values and useless columns\n",
    "train_df = train_df.dropna(how='any', axis=0)\n",
    "train_df = train_df.drop(columns=['id', 'customerid'])\n",
    "\n",
    "# impute the dataset\n",
    "cols = ['surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "for col in cols:\n",
    "    train_df = impute_target(train_df, col)\n",
    "\n",
    "# calculate the roc scores\n",
    "model = LGBMClassifier(objective='binary', **study.best_params)\n",
    "scores = calculate_score(train_df, model=model)\n",
    "print(f'The average score of the optimized model is {scores.mean(): .4f}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d260d375-7fa8-4c9e-9ef4-cc6c26e26c9b",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7eca3a9f-649e-4c6e-9fd7-18d2056cf2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_test(test_df, train_df, col):\n",
    "    # calcualted the mean exited rate by specified columns\n",
    "    df_target = train_df.groupby(col).agg({'exited': 'mean'})\n",
    "    df_target = df_target.reset_index()\n",
    "    df_target = df_target.rename(columns={'exited': col+'_target'})\n",
    "    \n",
    "    df = pd.merge(test_df, df_target, on=col, how='left', \n",
    "                  validate='m:1')\n",
    "    df = df.drop(columns=[col])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff225087-1c6d-40ca-8b0c-a7521604c6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset is (165034, 12).\n",
      "The shape of the testing dataset is (110023, 11).\n"
     ]
    }
   ],
   "source": [
    "# laod the training and testing dataset\n",
    "train_df = load_data('train')\n",
    "test_df = load_data('test')\n",
    "\n",
    "train_df.columns = train_df.columns.str.lower()\n",
    "test_df.columns = test_df.columns.str.lower()\n",
    "\n",
    "test_df.index = test_df.id\n",
    "\n",
    "train_df = train_df.drop(columns=['id', 'customerid'])\n",
    "test_df = test_df.drop(columns=['id', 'customerid'])\n",
    "\n",
    "# impute the testing dataset\n",
    "cols = ['surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "for col in cols:\n",
    "    test_df = impute_test(test_df, train_df, col)\n",
    "\n",
    "# impute the training dataset\n",
    "cols = ['surname', 'geography', 'gender', 'hascrcard', 'isactivemember']\n",
    "for col in cols:\n",
    "    train_df = impute_target(train_df, col)\n",
    "\n",
    "# fill the missing values of surname targets\n",
    "surname_mean = test_df.surname_target.mean()\n",
    "test_df = test_df.fillna(surname_mean)\n",
    "\n",
    "print(f'The shape of the training dataset is {train_df.shape}.')\n",
    "print(f'The shape of the testing dataset is {test_df.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7592c52-9fb7-407d-b40f-968833d70d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val = train_df.drop(columns=['exited'])\n",
    "y_train_val = train_df['exited']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, \n",
    "                                                    test_size=0.2, stratify=y_train_val, \n",
    "                                                    random_state=42)\n",
    "\n",
    "model = LGBMClassifier(objective='binary', **study.best_params)\n",
    "model.fit(X_train, y_train, \n",
    "          eval_set=[(X_val, y_val)], \n",
    "          verbose=0)\n",
    "test_proba = model.predict_proba(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34342c21-b69c-4f1a-9b9c-f5dddfb2cb13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165034</td>\n",
       "      <td>0.011312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>165035</td>\n",
       "      <td>0.688890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>165036</td>\n",
       "      <td>0.010176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>165037</td>\n",
       "      <td>0.136124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>165038</td>\n",
       "      <td>0.264510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id    Exited\n",
       "0  165034  0.011312\n",
       "1  165035  0.688890\n",
       "2  165036  0.010176\n",
       "3  165037  0.136124\n",
       "4  165038  0.264510"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = load_data('test')\n",
    "test_df['Exited'] = test_proba[:, 1]\n",
    "test_df = test_df[['id', 'Exited']]\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ecbe5f6e-83d1-4979-877a-afe3f6fdce92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('../data/playground_series_s4e1/submission.csv', \n",
    "              index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bdc8523e-7868-4733-b650-6e83928e994b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110023, 2)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd5c1a-84e9-4bf5-b706-2e76aee320fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GradientBoostingDecisionTrees",
   "language": "python",
   "name": "gradientboosting"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
